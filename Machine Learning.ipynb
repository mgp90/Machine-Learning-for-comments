{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning para libros\n",
    "\n",
    "Este proyecyo tiene la finalidad de predecir la puntuación que se ofrece a un libro según su comentario, utilizando como datos los comentarios y puntuaciones obtenidas de la tienda de Amazon en 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class Sentiment:\n",
    "    NEGATIVO = 'NEGATIVO'\n",
    "    NEUTRAL = 'NEUTRAL'\n",
    "    POSITIVO = 'POSITIVO'\n",
    "\n",
    "#Para que sea mas claro se crea una case con nombres:\n",
    "# text, score y sentimiento\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "# Para dar un nombre a la valoración numerica, se entiende como \"Sentimiento\"\n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVO\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: #4 y 5\n",
    "            return Sentiment.POSITIVO\n",
    "        \n",
    "# Contenedor de coemntarios\n",
    "\n",
    "class ReviewContainer:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews\n",
    "        \n",
    "        # Metodo para la optención del texto\n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "        \n",
    "        # Metodo para la optención del sentimiento\n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]\n",
    "        \n",
    "               \n",
    "        \n",
    "        # Metodo para filtrado de los sentimientos\n",
    "    def evenly_distribute(self):\n",
    "        positivo = list(filter(lambda x: x.sentiment == Sentiment.POSITIVO, self.reviews))\n",
    "        neutral = list(filter(lambda x: x.sentiment == Sentiment.NEUTRAL, self.reviews))\n",
    "        negativo = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVO, self.reviews))\n",
    "        \n",
    "        # Impresion para comprobación\n",
    "        print('Totalidad de negativos = ', len(negativo))\n",
    "        print('Totalidad de positivos = ', len(positivo))\n",
    "        print('Totalidad de neutrales = ', len(neutral))\n",
    "        positivos_reducido = positivo[:len(negativo)]\n",
    "        self.reviews = negativo + neutral + positivos_reducido\n",
    "        random.shuffle(self.reviews)\n",
    "        print('Totalidad de positivos y negativos = ', len(self.reviews))\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVO'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Dirección del archivo\n",
    "# Archivo con comentarios sobre libros en Amazon en 2014\n",
    "# Del cual se toma en consideración el contario en texto y valoración numerica.\n",
    "file_name = 'D:/Drive/MasterD/Datos varios/Coments_books.json'\n",
    "\n",
    "# Tomar reviewText y overall y se añade a la clase Review\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'], review['overall']))\n",
    "        \n",
    "reviews[5].sentiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670\n",
      "330\n"
     ]
    }
   ],
   "source": [
    "# Divide en dos los datos: test 33% y train el 66%\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training, test = train_test_split(reviews, test_size=0.33, random_state=42 )\n",
    "\n",
    "# Comprobación\n",
    "print(len(training))\n",
    "print(len(test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se divide texto y sentimiento en valores x y\n",
    "train_x = [x.text for x in training]\n",
    "train_y = [x.sentiment for x in training]\n",
    "\n",
    "test_x = [x.text for x in test]\n",
    "test_y = [x.sentiment for x in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con Sklearn vectorizamos las palabras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<670x7372 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 41455 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "train_x_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POSITIVO']\n",
      "['POSITIVO']\n"
     ]
    }
   ],
   "source": [
    "# Árbol de decisiones\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clasf_tree = DecisionTreeClassifier()\n",
    "# Entrenar \n",
    "clasf_tree.fit(train_x_vectors, train_y)\n",
    "\n",
    "#Se prueba con el primer comentario\n",
    "\n",
    "print(clasf_tree.predict(test_x_vectors[0]))\n",
    "\n",
    "# Y con el sexto\n",
    "\n",
    "print(clasf_tree.predict(test_x_vectors[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['POSITIVO']\n",
      "['NEUTRAL']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Regresión logistica\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clasf_log = LogisticRegression()\n",
    "# Entrenar\n",
    "clasf_log.fit(train_x_vectors, train_y)\n",
    "\n",
    "#Se prueba con el primer comentario\n",
    "\n",
    "print(clasf_log.predict(test_x_vectors[0]))\n",
    "\n",
    "# Y con el sexto\n",
    "\n",
    "print(clasf_log.predict(test_x_vectors[5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar los resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol de decisiones la exacitud es de  0.7757575757575758  %\n",
      "Regresión logistica la exacitud es de  0.8303030303030303  %\n"
     ]
    }
   ],
   "source": [
    "# Se toman los resultados de test en x(texto) comparado con y(sentimiento/valoración)\n",
    "# para valorar la exactitud\n",
    "print('Árbol de decisiones la exacitud es de ', clasf_tree.score(test_x_vectors, test_y), ' %')\n",
    "print('Regresión logistica la exacitud es de ', clasf_log.score(test_x_vectors, test_y),' %')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87737478 0.07142857 0.        ]\n",
      "[0.91370558 0.12244898 0.1       ]\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos los resultados con la precision y el recall con F1\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_tree = f1_score(test_y, clasf_tree.predict(test_x_vectors), average = None, labels=[Sentiment.POSITIVO, Sentiment.NEUTRAL, Sentiment.NEGATIVO ])\n",
    "f1_log = f1_score(test_y, clasf_log.predict(test_x_vectors), average = None, labels=[Sentiment.POSITIVO, Sentiment.NEUTRAL, Sentiment.NEGATIVO ])\n",
    "\n",
    "print(f1_tree)\n",
    "print(f1_log)\n",
    "\n",
    "# Se puede observar que los datos se predicen correctamente en los comentarios positivos,\n",
    "# Pero predicen erroneamente los cometarios neutrales y negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Positivos  552\n",
      "Total Neutrales  71\n",
      "Total Negativos  47\n"
     ]
    }
   ],
   "source": [
    "# Para buscar donde puede encontrarse el fallo, se estudia los datos con los que se han tomado.\n",
    "\n",
    "# Se cuenta la cantidad de cada Sentimiento en el grupo train\n",
    "print('Total Positivos ', train_y.count(Sentiment.POSITIVO))\n",
    "print('Total Neutrales ', train_y.count(Sentiment.NEUTRAL))\n",
    "print('Total Negativos ', train_y.count(Sentiment.NEGATIVO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Al estar tan desigualado la cantidad de Positivos, elentrenamiento se realiza desigualadamente, al no tener sentido usa solo 47 datos de las 3 variantes, se opta por ampliar los datos de 1.000 comentarios a 10.000 comentarios obtenidos de la misma fuente.\n",
    " \n",
    " # Inicio con nuevos datos\n",
    " \n",
    " ### Carga y Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totalidad de training =  6700\n",
      "Totalidad de test =  3300\n",
      "Totalidad de negativos =  436\n",
      "Totalidad de positivos =  5611\n",
      "Totalidad de neutrales =  653\n",
      "Totalidad de positivos y negativos =  1525\n",
      "Totalidad de negativos =  208\n",
      "Totalidad de positivos =  2767\n",
      "Totalidad de neutrales =  325\n",
      "Totalidad de positivos y negativos =  741\n"
     ]
    }
   ],
   "source": [
    "# Se toman los nuevos datos\n",
    "file_name_2 = 'D:/Drive/MasterD/Datos varios/Coments_books_10000.json'\n",
    "\n",
    "# Tomar reviewText y overall y se añade a la clase Review\n",
    "reviews = []\n",
    "with open(file_name_2) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'], review['overall']))\n",
    "        \n",
    "# Divide en dos los datos: test 33% y train el 66%\n",
    "training, test = train_test_split(reviews, test_size=0.33, random_state=42 )\n",
    "\n",
    "# Comprobación cantidad total divida en test y train\n",
    "print('Totalidad de training = ', len(training))\n",
    "print('Totalidad de test = ', len(test))\n",
    "\n",
    "\n",
    "# Se crea dos contenedores para cantidades iguales de positivos y negativos\n",
    "contenedor_train = ReviewContainer(training)\n",
    "contenedor_train.evenly_distribute()\n",
    "\n",
    "contenedor_test = ReviewContainer(test)\n",
    "contenedor_test.evenly_distribute()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "436\n"
     ]
    }
   ],
   "source": [
    "# Se divide texto y sentimiento en valores x y, pero esta vez por metodo.\n",
    "train_x = contenedor_train.get_text()\n",
    "train_y = contenedor_train.get_sentiment()\n",
    "test_x = contenedor_test.get_text()\n",
    "test_y = contenedor_test.get_sentiment()\n",
    "\n",
    "# Comprobación de que tanto el positivo como el negativo sea la misma cantidad de datos\n",
    "print(train_y.count(Sentiment.POSITIVO))\n",
    "print(train_y.count(Sentiment.NEGATIVO))\n",
    "\n",
    "\n",
    "# Se vectorizan las palabras \n",
    "vectorizer = CountVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "test_x_vectors = vectorizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primer comentario, con árbol de decisiones  ['POSITIVO']\n",
      "Primer comentario, con regresión Log  ['NEGATIVO']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Árbol de decisiones\n",
    "clasf_tree = DecisionTreeClassifier()\n",
    "\n",
    "# Entrenar \n",
    "clasf_tree.fit(train_x_vectors, train_y)\n",
    "\n",
    "#Se prueba con el primer comentario\n",
    "\n",
    "print('Primer comentario, con árbol de decisiones ', clasf_tree.predict(test_x_vectors[0]))\n",
    "\n",
    "# Regresión logistica\n",
    "clasf_log = LogisticRegression()\n",
    "\n",
    "# Entrenar\n",
    "clasf_log.fit(train_x_vectors, train_y)\n",
    "\n",
    "#Se prueba con el primer comentario\n",
    "\n",
    "print('Primer comentario, con regresión Log ',clasf_log.predict(test_x_vectors[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se evaluan los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol de decisiones la exacitud es de  0.4534412955465587  %\n",
      "Regresión logistica la exacitud es de  0.6005398110661269  %\n"
     ]
    }
   ],
   "source": [
    "# Se toman los resultados de test en x(texto) comparado con y(sentimiento/valoración)\n",
    "# para valorar la exactitud\n",
    "print('Árbol de decisiones la exacitud es de ', clasf_tree.score(test_x_vectors, test_y), ' %')\n",
    "print('Regresión logistica la exacitud es de ', clasf_log.score(test_x_vectors, test_y),' %')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 con árbol de decisiones =  [0.42469136 0.50909091 0.39328537]\n",
      "F1 con regresión log. =  [0.63546798 0.61102832 0.54814815]\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos con F1\n",
    "\n",
    "f1_tree = f1_score(test_y, clasf_tree.predict(test_x_vectors), average = None, labels=[Sentiment.POSITIVO, Sentiment.NEUTRAL, Sentiment.NEGATIVO ])\n",
    "f1_log = f1_score(test_y, clasf_log.predict(test_x_vectors), average = None, labels=[Sentiment.POSITIVO, Sentiment.NEUTRAL, Sentiment.NEGATIVO ])\n",
    "\n",
    "print('F1 con árbol de decisiones = ', f1_tree)\n",
    "print('F1 con regresión log. = ',f1_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que se ha mejorado la exactidud de las predicciones, siendo la regresión Log. la que mejor se aproxima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso en ejemplos\n",
    "\n",
    "El modelo esta entrenado y listo para su uso con ejemplos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVO', 'NEGATIVO', 'POSITIVO', 'POSITIVO'], dtype='<U8')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = ['not great', 'really bad book', 'best option', 'great time reading it']\n",
    "new_test = vectorizer.transform(test_set)\n",
    "clasf_log.predict(new_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
